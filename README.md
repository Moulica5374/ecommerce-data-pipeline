# ğŸ›’ E-Commerce Data Pipeline

An end-to-end data engineering project implementing a Bronze-Silver-Gold architecture to process and analyze 540K+ e-commerce transactions.

![Python](https://img.shields.io/badge/Python-3.11-blue)
![PySpark](https://img.shields.io/badge/PySpark-3.5-orange)
![AWS](https://img.shields.io/badge/AWS-S3%20%7C%20Athena-yellow)
![Status](https://img.shields.io/badge/Status-Complete-success)

---

## ğŸ“Š Project Overview

Built a scalable data pipeline that processes e-commerce transaction data through multiple transformation layers, implementing data quality checks and generating business insights through interactive visualizations.

**Key Achievement:** Cleaned 541,909 transactions, removing 0.46% of bad data while retaining 99%+ of revenue data for analysis.

---

## ğŸ—ï¸ Architecture
```
Raw Data (CSV)
    â†“
Bronze Layer (S3) - Raw data storage
    â†“
Apache Spark - Data cleaning & transformation
    â†“
Silver Layer (S3) - Cleaned, validated data
    â†“
Gold Layer (S3) - Business aggregations
    â†“
AWS Athena - SQL analytics
    â†“
Visualizations - Interactive dashboards
```

---

## ğŸ› ï¸ Tech Stack

- **Data Processing:** Apache Spark (PySpark), Python, Pandas
- **Cloud Storage:** AWS S3 (Bronze/Silver/Gold layers)
- **Data Format:** Parquet (columnar, compressed)
- **Query Engine:** AWS Athena
- **Visualization:** Plotly (interactive charts)
- **Development:** Google Colab, Jupyter Notebooks
- **Version Control:** Git, GitHub

---

## ğŸ“ˆ Key Business Insights

### Revenue Analysis
- **Total Revenue:** $9.75M across 12 months
- **Top Market:** United Kingdom (92% of total revenue - $9.03M)
- **Growth Rate:** 83% increase from Dec 2010 ($824K) to Nov 2011 ($1.51M)

### Product Performance
- **Best Seller:** DOTCOM POSTAGE ($206K revenue)
- **Top 10 Products:** Contribute $1.2M in revenue
- **Popular Categories:** Home decor, gift items, party supplies

### Customer Segments
- **Registered Customers:** 406,789 transactions (75.4%)
- **Guest Purchases:** 132,603 transactions (24.6%, $1.73M revenue)
- **Returns:** 9,288 transactions properly tracked

---

## ğŸ“Š Visualizations

### Sales by Country
Top performing countries by revenue:

[Interactive Chart](images/sales_by_country.html) | [View Code](notebooks/)

### Top Products
Best-selling products analysis:

[Interactive Chart](images/top_products.html)

### Monthly Revenue Trend
Revenue growth over time showing seasonal patterns:

[Interactive Chart](images/monthly_revenue.html)

---

## ğŸ”„ Data Pipeline Process

### 1ï¸âƒ£ Bronze Layer (Raw Data)
- Source: Kaggle E-commerce dataset
- Format: CSV (541,909 rows, 8 columns)
- Storage: `s3://bucket/raw/data.csv`

### 2ï¸âƒ£ Silver Layer (Data Cleaning)

**Data Quality Issues Identified:**
- 135,080 NULL CustomerIDs (24.9%)
- 10,624 negative quantities
- 2,517 bad prices (â‰¤ $0)
- 1,454 NULL descriptions

**Transformations Applied:**
```python
âœ… Removed 2,517 bad records (0.46%)
âœ… Created customer_type: "Guest" vs "Registered"
âœ… Added is_return flag for returns tracking
âœ… Filled NULL descriptions with "Unknown Product"
âœ… Created TotalPrice: Quantity Ã— UnitPrice
âœ… Parsed dates: Extracted Year, Month, Day, Hour
```

**Result:** 539,392 clean records in Parquet format

### 3ï¸âƒ£ Gold Layer (Business Aggregations)

Created analytical tables:
- **Sales by Country:** Revenue, order count, unique customers per country
- **Top Products:** Best sellers by revenue and quantity
- **Monthly Revenue:** Time-series analysis of sales trends

---

## ğŸ’¡ Data Engineering Decisions

### Why Keep Guest Purchases?
Initially considered dropping NULL CustomerIDs, but analysis revealed:
- 132K transactions = 24.6% of data
- $1.73M revenue = 17.8% of total revenue
- **Decision:** Segment as "Guest" customers rather than delete

### Why Remove Internal Adjustments?
Identified 1,336 records with:
- Negative quantities without "C" prefix (not customer returns)
- Descriptions like "damages", "faulty", "check"
- No customer information
- **Decision:** These are operational adjustments, not sales transactions

### Why Use Parquet Format?
- 70-80% compression vs CSV
- Columnar storage for fast queries
- Native support in Spark, Athena, and modern data tools

---

## ğŸš€ How to Run

### Prerequisites
```bash
- Python 3.8+
- Apache Spark 3.5+
- AWS CLI configured
- AWS S3 bucket access
```

### Setup
```bash
# Clone repository
git clone https://github.com/yourusername/ecommerce-data-pipeline.git
cd ecommerce-data-pipeline

# Install dependencies
pip install pyspark pandas plotly boto3 awswrangler

# Configure AWS credentials
aws configure
```

### Run Pipeline
```bash
# Open Jupyter notebook
jupyter notebook notebooks/Ecommerce_Silver_Layer_Transformation.ipynb

# Or run in Google Colab
# Upload notebook and data.csv
```

---

## ğŸ“ Project Structure
```
ecommerce-data-pipeline/
â”œâ”€â”€ README.md
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA_Investigation.ipynb
â”‚   â””â”€â”€ 02_Silver_Layer_Transformation.ipynb
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ sales_by_country.html
â”‚   â”œâ”€â”€ top_products.html
â”‚   â””â”€â”€ monthly_revenue.html
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ architecture.md
â””â”€â”€ data/
    â””â”€â”€ sample_data.csv
```

---

## ğŸ¯ Skills Demonstrated

âœ… Data Quality Analysis & Cleaning  
âœ… ETL Pipeline Design (Bronze-Silver-Gold)  
âœ… Apache Spark (PySpark) Transformations  
âœ… AWS S3 Data Lake Architecture  
âœ… SQL Query Optimization (Athena)  
âœ… Data Visualization & Storytelling  
âœ… Business Logic Implementation  
âœ… Cloud Data Engineering (AWS)

---

## ğŸ”® Future Enhancements

- [ ] Apache Airflow orchestration for automated daily runs
- [ ] AWS Glue jobs for cloud-based Spark processing
- [ ] Real-time streaming with AWS Kinesis
- [ ] Advanced analytics: Customer segmentation, RFM analysis
- [ ] ML models: Demand forecasting, churn prediction
- [ ] CI/CD pipeline with GitHub Actions
- [ ] Data quality monitoring with Great Expectations

---

## ğŸ“ License

This project is open source and available under the MIT License.

---

## ğŸ‘¤ Author

**Your Name**
- LinkedIn: [your-profile](https://linkedin.com/in/yourprofile)
- GitHub: [@yourusername](https://github.com/yourusername)
- Email: your.email@example.com

---

## ğŸ™ Acknowledgments

- Dataset: [Online Retail Dataset](https://www.kaggle.com/datasets/vijayuv/onlineretail) from Kaggle
- Tools: Apache Spark, AWS, Plotly

---

**â­ If you found this project helpful, please give it a star!**
